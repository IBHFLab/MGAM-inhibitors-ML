{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "567a83dd-2fba-4cd3-bdeb-057496f8a32a",
   "metadata": {},
   "source": [
    "## 数据集划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab6c8dc0-ad35-42ce-91a7-231370b3f02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\usual\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "d:\\anaconda\\envs\\usual\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "d:\\anaconda\\envs\\usual\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前工作目录: d:\\Issue\\2024_2025\\夏雨婷文章\\md06\\xyt\\md05\\02分子指纹\n"
     ]
    }
   ],
   "source": [
    "# 导入必要的库\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# 检查当前工作目录\n",
    "current_directory = os.getcwd()\n",
    "print(\"当前工作目录:\", current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e819720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imblearn是处理不平衡数据集的库，包括过采样和欠采样方法\n",
    "from imblearn.datasets import make_imbalance          \n",
    "from imblearn.over_sampling import KMeansSMOTE,SMOTE,SVMSMOTE\n",
    "from imblearn.under_sampling import AllKNN,CondensedNearestNeighbour,NearMiss\n",
    "from imblearn.combine import SMOTEENN,SMOTETomek\n",
    "# sklearn提供机器学习模型和数据处理工具\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification, make_moons\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import average_precision_score\n",
    "# 配置Jupyter Notebook环境\n",
    "# 设置高分辨率图像输出\n",
    "%config InlineBackend.figure_format='retina'\n",
    "# 设置matplotlib图形直接在Jupyter Notebook中显示\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56195e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入os模块和计数器\n",
    "import os\n",
    "from collections import Counter\n",
    "# 导入RDKit模块，用于化学信息学处理\n",
    "import rdkit as rd\n",
    "from rdkit.Chem.Fingerprints import FingerprintMols\n",
    "from rdkit import RDConfig\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdFingerprintGenerator\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem.rdMolDescriptors import GetAtomPairFingerprint\n",
    "from rdkit.Avalon import pyAvalonTools\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.AtomPairs import Pairs, Torsions\n",
    "# 导入更多机器学习和模型评估工具\n",
    "import sklearn as sk\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# 导入绘图库\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8347009a-bc75-4535-9b7d-085a0dbadf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入数据处理和模型选择工具\n",
    "from sklearn.utils import shuffle \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc,roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.model_selection import GridSearchCV, cross_val_score,train_test_split,cross_validate, StratifiedKFold\n",
    "from sklearn.utils  import shuffle\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18885bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"D://Issue/2024_2025/夏雨婷文章/md05/xyt/md04/2-分子指纹/指纹表征/version-1/dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46668eff-50e9-4b7f-95c5-ff4061a80dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取并划分数据集\n",
    "data = pd.read_csv('bioactivity_preprocessed_MGAM.csv')\n",
    "x = data[\"canonical_smiles\"]  # SMILES字符串作为特征\n",
    "y = data[\"bioactivity_class\"]    # 生物活性类别作为目标变量\n",
    "#x_mor_train和x_mor_test分别为训练集和测试集中的特征数据，y_mor_train和y_mor_test分别为训练集和测试集中的目标变量数据。\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y,random_state=13)\n",
    "#test_size=0.2: 测试集大小占总数据的20%\n",
    "#stratify=y: 划分时保持y中的类别比例，确保训练集和测试集中各类别的比例与原始数据集相同\n",
    "#random_state=13：设置随机数种子以确保结果的可重复性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "994b508a-9411-4963-ad3c-5f3b14f22dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集特征维度: (605,)\n",
      "训练集目标维度: (605,)\n",
      "测试集特征维度: (152,)\n",
      "测试集目标维度: (152,)\n"
     ]
    }
   ],
   "source": [
    "# 打印训练集和测试集的维度，确认划分正确\n",
    "print(\"训练集特征维度:\", x_train.shape)\n",
    "print(\"训练集目标维度:\", y_train.shape)\n",
    "print(\"测试集特征维度:\", x_test.shape)\n",
    "print(\"测试集目标维度:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51b35f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将划分的数据集保存为CSV文件\n",
    "x_train.to_csv('train_features.csv', index=False)  # 保存训练集特征\n",
    "y_train.to_csv('train_target.csv', index=False)  # 保存训练集目标变量\n",
    "x_test.to_csv('test_features.csv', index=False)  # 保存测试集特征\n",
    "y_test.to_csv('test_target.csv', index=False)  # 保存测试集目标变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0d03ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将特征和目标变量合并后再次保存，方便后续处理\n",
    "train_data = pd.concat([x_train, y_train], axis=1)\n",
    "train_data.to_csv('train_dataset.csv', index=False)  # 保存训练数据集\n",
    "test_data = pd.concat([x_test, y_test], axis=1)\n",
    "test_data.to_csv('test_dataset.csv', index=False)  # 保存测试数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955ac7ed-b102-4192-bdef-fee9f04d444e",
   "metadata": {},
   "source": [
    "## 分子指纹表征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6414ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取测试数据集\n",
    "ar2 = pd.read_csv('test_dataset.csv')\n",
    "\n",
    "# 初始化一个列表来存储Canonical SMILES\n",
    "Canonical_SMILES = []\n",
    "# 遍历数据集中的canonical_smiles列，并将其值添加到列表中\n",
    "for i in ar2.canonical_smiles:\n",
    "    Canonical_SMILES.append(i)\n",
    "\n",
    "# 将Canonical SMILES列表复制给新变量\n",
    "ar1_smiles = Canonical_SMILES\n",
    "\n",
    "# 初始化一个列表来存储规范化后的SMILES字符串\n",
    "c_smiles = []\n",
    "# 遍历SMILES字符串\n",
    "for ds in ar1_smiles:\n",
    "    try:\n",
    "         # 尝试使用RDKit的Chem.CanonSmiles函数规范化SMILES字符串\n",
    "        cs = Chem.CanonSmiles(ds)\n",
    "        # 如果成功，添加到列表中\n",
    "        c_smiles.append(cs)\n",
    "    except:\n",
    "        # 如果规范化失败，打印失败的SMILES字符串\n",
    "        print('Invalid SMILES:', ds)\n",
    "\n",
    "# 将规范化的SMILES字符串转换为RDKit分子对象\n",
    "ms = [Chem.MolFromSmiles(x) for x in c_smiles]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d727860d-c796-4866-8f68-64b8d601b152",
   "metadata": {},
   "source": [
    "### 扩展连通性指纹 (Extended Connectivity FingerPrints, ECFPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9eca7073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为每个分子生成Morgan指纹，指定半径为2，位数为2048\n",
    "Morganfps = [AllChem.GetMorganFingerprintAsBitVect(x, 2, nBits=2048) for x in ms]\n",
    "\n",
    "# 将生成的Morgan指纹写入到文件中\n",
    "with open('morganfps.txt','a') as c:\n",
    "    for i in range(len(Morganfps)):\n",
    "        # 将指纹转换为位字符串\n",
    "        str1 = Morganfps[i].ToBitString()\n",
    "        # 遍历位字符串，写入每一位，并用逗号分隔\n",
    "        for j in str1:\n",
    "            c.write(str(int(j))+',')\n",
    "        # 每个指纹结束后换行    \n",
    "        c.write('\\n')\n",
    "    # 文件操作完成后自动关闭\n",
    "    c.close()\n",
    "\n",
    "# 读取保存的Morgan指纹文件   \n",
    "ecfp4 = open(\"morganfps.txt\",\"r\",encoding='utf-8') \n",
    "MF_ecfp4=[]\n",
    "# 逐行读取文件内容\n",
    "for line in ecfp4.readlines():\n",
    "    # 按逗号分隔每一行，转换成列表\n",
    "    line=line.split(',')\n",
    "    # 添加到列表中\n",
    "    MF_ecfp4.append(line)\n",
    "# 关闭文件 \n",
    "ecfp4.close() \n",
    "\n",
    "# 将读取的数据转换为DataFrame，并去掉最后一个空列（因为每行末尾有一个逗号）\n",
    "MF_ecfp4=pd.DataFrame(MF_ecfp4,index = None)\n",
    "MF_ecfp4 = MF_ecfp4.drop(MF_ecfp4.columns[-1],axis=1)\n",
    "\n",
    "# 从原始数据中提取canonical_smiles和bioactivity_class列\n",
    "Y = ar2[[\"canonical_smiles\",\"bioactivity_class\"]]\n",
    "# 将这两列与Morgan指纹的DataFrame合并\n",
    "ar3 = pd.concat([Y,MF_ecfp4], axis=1)\n",
    "# 将合并后的数据保存到新的CSV文件\n",
    "ar3.to_csv('MGAM-test-ecfps.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3cb1af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为每个分子生成Morgan指纹，指定半径为2，位数为2048\n",
    "Morganfps = [AllChem.GetMorganFingerprintAsBitVect(x, 2, nBits=2048) for x in ms]\n",
    "\n",
    "# 将生成的Morgan指纹写入到文件中\n",
    "with open('morganfps.txt','a') as c:\n",
    "    for i in range(len(Morganfps)):\n",
    "        # 将指纹转换为位字符串\n",
    "        str1 = Morganfps[i].ToBitString()\n",
    "        # 遍历位字符串，写入每一位，并用逗号分隔\n",
    "        for j in str1:\n",
    "            c.write(str(int(j))+',')\n",
    "        # 每个指纹结束后换行    \n",
    "        c.write('\\n')\n",
    "    # 文件操作完成后自动关闭\n",
    "    c.close()\n",
    "\n",
    "# 读取保存的Morgan指纹文件   \n",
    "ecfp4 = open(\"morganfps.txt\",\"r\",encoding='utf-8') \n",
    "MF_ecfp4=[]\n",
    "# 逐行读取文件内容\n",
    "for line in ecfp4.readlines():\n",
    "    # 按逗号分隔每一行，转换成列表\n",
    "    line=line.split(',')\n",
    "    # 添加到列表中\n",
    "    MF_ecfp4.append(line)\n",
    "# 关闭文件 \n",
    "ecfp4.close() \n",
    "\n",
    "# 将读取的数据转换为DataFrame，并去掉最后一个空列（因为每行末尾有一个逗号）\n",
    "MF_ecfp4=pd.DataFrame(MF_ecfp4,index = None)\n",
    "MF_ecfp4 = MF_ecfp4.drop(MF_ecfp4.columns[-1],axis=1)\n",
    "\n",
    "# 从原始数据中提取canonical_smiles和bioactivity_class列\n",
    "Y = ar2[[\"canonical_smiles\",\"bioactivity_class\"]]\n",
    "# 将这两列与Morgan指纹的DataFrame合并\n",
    "ar3 = pd.concat([Y,MF_ecfp4], axis=1)\n",
    "# 将合并后的数据保存到新的CSV文件\n",
    "ar3.to_csv('MGAM-test-ecfps.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ef3286-7473-4b1d-a895-ab9d300feae1",
   "metadata": {},
   "source": [
    "### 功能类圆形指纹（Functional-Class Fingerprints, FCFPs）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc44c379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成分子的FCFPs（功能类圆形指纹），半径为2，位数为2048，使用特征（useFeatures=True）\n",
    "FCFPs = [AllChem.GetMorganFingerprintAsBitVect(x, 2, nBits=2048, useFeatures=True) for x in ms]\n",
    "\n",
    "# 将生成的FCFPs写入到txt文件中\n",
    "with open('fcfps.txt','a') as c:\n",
    "    for i in range(len(FCFPs)):\n",
    "        # 将每个指纹转换为位字符串\n",
    "        str1 = FCFPs[i].ToBitString()\n",
    "        # 遍历位字符串，并将每一位后跟逗号写入文件\n",
    "        for j in str1:\n",
    "            c.write(str(int(j))+',')\n",
    "        # 每个指纹后换行\n",
    "        c.write('\\n')\n",
    "    # 文件操作完成后自动关闭\n",
    "    c.close()\n",
    "\n",
    "# 读取保存的FCFPs文件\n",
    "ecfp4 = open(\"fcfps.txt\",\"r\",encoding='utf-8') \n",
    "MF_ecfp4=[]\n",
    "# 逐行读取文件中的内容\n",
    "for line in ecfp4.readlines():\n",
    "    # 按逗号分割每行，转换成列表\n",
    "    line=line.split(',')\n",
    "    # 将分割后的列表添加到MF_ecfp4列表中\n",
    "    MF_ecfp4.append(line)\n",
    "# 关闭文件  \n",
    "ecfp4.close() \n",
    "\n",
    "# 将读取的数据转换为DataFrame，并删除最后一个空列（因为每行末尾有多余的逗号）\n",
    "MF_ecfp4=pd.DataFrame(MF_ecfp4,index = None)\n",
    "MF_ecfp4 = MF_ecfp4.drop(MF_ecfp4.columns[-1],axis=1)\n",
    "\n",
    "# 从原始数据集中提取canonical_smiles和bioactivity_class列\n",
    "Y = ar2[[\"canonical_smiles\",\"bioactivity_class\"]]\n",
    "\n",
    "# 将提取的列与FCFPs数据合并\n",
    "ar3 = pd.concat([Y,MF_ecfp4], axis=1)\n",
    "\n",
    "# 将合并后的数据保存到新的CSV文件\n",
    "ar3.to_csv('MGAM-test-fcfps.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaabe0a-3234-4a80-b99b-b02f6b6a8965",
   "metadata": {},
   "source": [
    "### Avalon指纹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f0a7b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成Avalon指纹：对ms列表中的每个分子对象x生成Avalon指纹\n",
    "Avalonfps = [pyAvalonTools.GetAvalonFP(x) for x in ms]\n",
    "\n",
    "# 打开（或创建）'avalonfps.txt'文件以追加模式\n",
    "with open('avalonfps.txt','a') as c:\n",
    "    # 遍历所有生成的Avalon指纹\n",
    "    for i in range(len(Avalonfps)):\n",
    "        # 将指纹转换为位字符串\n",
    "        str1 = Avalonfps[i].ToBitString()\n",
    "         # 遍历位字符串中的每一位，并将其写入文件，每位之间用逗号分隔\n",
    "        for j in str1:\n",
    "            c.write(str(int(j))+',')\n",
    "        # 每个指纹的位字符串结束后换行\n",
    "        c.write('\\n')\n",
    "    # 文件操作完成后自动关闭\n",
    "    c.close()\n",
    "\n",
    "# 读取'avalonfps.txt'文件\n",
    "ecfp4 = open(\"avalonfps.txt\",\"r\",encoding='utf-8') \n",
    "MF_ecfp4=[]\n",
    "# 逐行读取文件内容\n",
    "for line in ecfp4.readlines():\n",
    "    # 将每行按逗号分割，转换成列表\n",
    "    line=line.split(',')\n",
    "    # 将处理后的列表添加到MF_ecfp4列表中\n",
    "    MF_ecfp4.append(line)\n",
    "# 关闭文件\n",
    "ecfp4.close()\n",
    "\n",
    "# 将读取的指纹数据转换为DataFrame\n",
    "MF_ecfp4=pd.DataFrame(MF_ecfp4,index = None)\n",
    "# 删除DataFrame中最后一个空列，这个空列是由于每行结尾的逗号导致的\n",
    "MF_ecfp4 = MF_ecfp4.drop(MF_ecfp4.columns[-1],axis=1)\n",
    "\n",
    "# 从原始数据集ar2中提取canonical_smiles和bioactivity_class列\n",
    "Y = ar2[[\"canonical_smiles\",\"bioactivity_class\"]]\n",
    "\n",
    "# 将提取的列与Avalon指纹数据合并\n",
    "ar3 = pd.concat([Y,MF_ecfp4], axis=1)\n",
    "\n",
    "# 将合并后的数据保存到新的CSV文件'MGAM-test-avalonfps.csv'\n",
    "ar3.to_csv('MGAM-test-avalonfps.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e8fe57-56b3-4653-8179-7e88a498a167",
   "metadata": {},
   "source": [
    "### MACCS指纹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8625708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为列表中的每个分子生成MACCS指纹\n",
    "MACCS = [AllChem.GetMACCSKeysFingerprint(x) for x in ms]\n",
    "\n",
    "# 打开（或创建）'maccs.txt'文件以追加模式写入MACCS指纹数据\n",
    "with open('maccs.txt','a') as c:\n",
    "    for i in range(len(MACCS)):\n",
    "         # 将每个指纹转换为位字符串\n",
    "        str1 = MACCS[i].ToBitString()\n",
    "        # 遍历位字符串，并将每一位后跟逗号写入文件\n",
    "        for j in str1:\n",
    "            c.write(str(int(j))+',')\n",
    "        # 每个指纹的位字符串结束后换行\n",
    "        c.write('\\n')\n",
    "    # 文件写入完成后自动关闭\n",
    "    c.close()\n",
    "\n",
    "# 读取保存的'maccs.txt'文件\n",
    "ecfp4 = open(\"maccs.txt\",\"r\",encoding='utf-8') \n",
    "MF_ecfp4=[]\n",
    "# 逐行读取文件中的内容\n",
    "for line in ecfp4.readlines():\n",
    "    # 将每行按逗号分割，转换成列表\n",
    "    line=line.split(',')\n",
    "    # 将处理后的列表添加到MF_ecfp4列表中\n",
    "    MF_ecfp4.append(line)\n",
    "# 关闭文件\n",
    "ecfp4.close() \n",
    "\n",
    "# 将读取的数据转换为DataFrame\n",
    "MF_ecfp4=pd.DataFrame(MF_ecfp4,index = None)\n",
    "# 删除DataFrame中最后一个空列，这个空列是由于每行结尾的逗号导致的\n",
    "MF_ecfp4 = MF_ecfp4.drop(MF_ecfp4.columns[-1],axis=1)\n",
    "\n",
    "# 从原始数据集中提取canonical_smiles和bioactivity_class列\n",
    "Y = ar2[[\"canonical_smiles\",\"bioactivity_class\"]]\n",
    "\n",
    "# 将提取的列与MACCS指纹数据合并\n",
    "ar3 = pd.concat([Y,MF_ecfp4], axis=1)\n",
    "\n",
    "# 将合并后的数据保存到新的CSV文件\n",
    "ar3.to_csv('MGAM-test-maccs.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a654439a-1f56-4237-8ea2-5f275416837a",
   "metadata": {},
   "source": [
    "### RDKit指纹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4778c6c9-1c26-4749-b204-d7e0316c905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为ms列表中的每个分子生成RDK指纹，设置最大路径长度为5，指纹大小为2048位\n",
    "RDKfps = [Chem.RDKFingerprint(x,maxPath=5,fpSize=2048) for x in ms]\n",
    "\n",
    "# 打开（或创建）'rdkfps.txt'文件，以追加模式写入RDK指纹数据\n",
    "with open('rdkfps.txt','a') as c:\n",
    "    for i in range(len(RDKfps)):\n",
    "        # 将每个指纹转换为位字符串\n",
    "        str1 = RDKfps[i].ToBitString()\n",
    "        # 遍历位字符串，并将每一位后跟逗号写入文件\n",
    "        for j in str1:\n",
    "            c.write(str(int(j))+',')\n",
    "        # 每个指纹的位字符串结束后换行\n",
    "        c.write('\\n')\n",
    "    # 文件操作完成后自动关闭\n",
    "    c.close()\n",
    "\n",
    "# 读取保存的'rdkfps.txt'文件\n",
    "ecfp4 = open(\"rdkfps.txt\",\"r\",encoding='utf-8') \n",
    "MF_ecfp4=[]\n",
    "# 逐行读取文件中的内容\n",
    "for line in ecfp4.readlines():\n",
    "    # 将每行按逗号分割，转换成列表\n",
    "    line=line.split(',')\n",
    "    # 将处理后的列表添加到MF_ecfp4列表中\n",
    "    MF_ecfp4.append(line)\n",
    "# 关闭文件\n",
    "ecfp4.close() \n",
    "\n",
    "# 将读取的指纹数据转换为DataFrame\n",
    "MF_ecfp4=pd.DataFrame(MF_ecfp4,index = None)\n",
    "# 删除DataFrame中最后一个空列，这个空列是由于每行结尾的逗号导致的\n",
    "MF_ecfp4 = MF_ecfp4.drop(MF_ecfp4.columns[-1],axis=1)\n",
    "\n",
    "# 从原始数据集中提取canonical_smiles和bioactivity_class列\n",
    "Y = ar2[[\"canonical_smiles\",\"bioactivity_class\"]]\n",
    "\n",
    "# 将提取的列与RDK指纹数据合并\n",
    "ar3 = pd.concat([Y,MF_ecfp4], axis=1)\n",
    "\n",
    "# 将合并后的数据保存到新的CSV文件\n",
    "ar3.to_csv('MGAM-test-rdkfps.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b226fe5-3a96-49ea-8f6a-f35003d4a5bf",
   "metadata": {},
   "source": [
    "### 生成散列化的原子对（Atom Pair, AP）指纹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b5843f3-824f-492a-bbba-fabc15ca0b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import rdMolDescriptors\n",
    "# 为ms列表中的每个分子生成散列化的原子对指纹\n",
    "APfps = [rdMolDescriptors.GetHashedAtomPairFingerprintAsBitVect(x) for x in ms]\n",
    "\n",
    "# 打开（或创建）'apfps.txt'文件，以追加模式写入散列化的原子对指纹数据\n",
    "with open('apfps.txt','a') as c:\n",
    "    # 遍历所有生成的散列化的原子对指纹\n",
    "    for i in range(len(APfps)):\n",
    "        # 将每个指纹转换为位字符串\n",
    "        str1 = APfps[i].ToBitString()\n",
    "        # 遍历位字符串，并将每一位后跟逗号写入文件\n",
    "        for j in str1:\n",
    "            c.write(str(int(j))+',')\n",
    "        # 每个指纹的位字符串结束后换行\n",
    "        c.write('\\n')\n",
    "    # 文件操作完成后自动关闭\n",
    "    c.close()\n",
    "\n",
    "# 读取保存的'apfps.txt'文件\n",
    "ecfp4 = open(\"apfps.txt\",\"r\",encoding='utf-8') \n",
    "MF_ecfp4=[]\n",
    "# 逐行读取文件中的内容\n",
    "for line in ecfp4.readlines():\n",
    "    # 将每行按逗号分割，转换成列表\n",
    "    line=line.split(',')\n",
    "    # 将处理后的列表添加到MF_ecfp4列表中\n",
    "    MF_ecfp4.append(line)\n",
    "# 关闭文件\n",
    "ecfp4.close() \n",
    "\n",
    "# 将读取的指纹数据转换为DataFrame\n",
    "MF_ecfp4=pd.DataFrame(MF_ecfp4,index = None)\n",
    "# 删除DataFrame中最后一个空列，这个空列是由于每行结尾的逗号导致的\n",
    "MF_ecfp4 = MF_ecfp4.drop(MF_ecfp4.columns[-1],axis=1)\n",
    "\n",
    "# 从原始数据集中提取canonical_smiles和bioactivity_class列\n",
    "Y = ar2[[\"canonical_smiles\",\"bioactivity_class\"]]\n",
    "\n",
    "# 将提取的列与散列化的原子对指纹数据合并\n",
    "ar3 = pd.concat([Y,MF_ecfp4], axis=1)\n",
    "\n",
    "# 将合并后的数据保存到新的CSV文件\n",
    "ar3.to_csv('MGAM-test-apfps.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96cf4c3-7df8-4976-a7bf-32a971204041",
   "metadata": {},
   "source": [
    "### 生成散列化的拓扑扭转（Topological Torsion）指纹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14b33d0b-6e9b-4001-94f0-d3351446a883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为ms列表中的每个分子生成散列化的拓扑扭转（Topological Torsion）指纹\n",
    "Topfps = [rdMolDescriptors.GetHashedTopologicalTorsionFingerprintAsBitVect(x) for x in ms]\n",
    "\n",
    "# 打开（或创建）'topfps.txt'文件，以追加模式写入拓扑扭转指纹数据\n",
    "with open('topfps.txt','a') as c:\n",
    "    # 遍历所有生成的拓扑扭转指纹\n",
    "    for i in range(len(Topfps)):#将RDKfps修改为Topfps\n",
    "        # 将每个指纹转换为位字符串\n",
    "        str1 = RDKfps[i].ToBitString()\n",
    "        # 遍历位字符串，并将每一位后跟逗号写入文件\n",
    "        for j in str1:\n",
    "            c.write(str(int(j))+',')\n",
    "        # 每个指纹的位字符串结束后换行\n",
    "        c.write('\\n')\n",
    "    # 文件操作完成后自动关闭\n",
    "    c.close()\n",
    "\n",
    "# 读取保存的'topfps.txt'文件\n",
    "ecfp4 = open(\"topfps.txt\",\"r\",encoding='utf-8') \n",
    "MF_ecfp4=[]\n",
    "# 逐行读取文件中的内容\n",
    "for line in ecfp4.readlines():\n",
    "    # 将每行按逗号分割，转换成列表\n",
    "    line=line.split(',')\n",
    "    # 将处理后的列表添加到MF_ecfp4列表中\n",
    "    MF_ecfp4.append(line)\n",
    "# 关闭文件\n",
    "ecfp4.close() \n",
    "\n",
    "# 将读取的指纹数据转换为DataFrame\n",
    "MF_ecfp4=pd.DataFrame(MF_ecfp4,index = None)\n",
    "# 删除DataFrame中最后一个空列，这个空列是由于每行结尾的逗号导致的\n",
    "MF_ecfp4 = MF_ecfp4.drop(MF_ecfp4.columns[-1],axis=1)\n",
    "\n",
    "# 从原始数据集中提取canonical_smiles和bioactivity_class列\n",
    "Y = ar2[[\"canonical_smiles\",\"bioactivity_class\"]]\n",
    "\n",
    "# 将提取的列与拓扑扭转指纹数据合并\n",
    "ar3 = pd.concat([Y,MF_ecfp4], axis=1)\n",
    "\n",
    "# 将合并后的数据保存到新的CSV文件\n",
    "ar3.to_csv('MGAM-test-topfps.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9453e5-0457-4a59-b523-eff250378999",
   "metadata": {},
   "source": [
    "### 药效团（Pharmacophore）指纹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1b0e60cb-4d6b-4583-b126-6dd445c99fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入RDKit的药效团指纹模块\n",
    "from rdkit.Chem.Pharm2D import Gobbi_Pharm2D, Generate\n",
    "\n",
    "# 为列表中的每个分子生成药效团指纹\n",
    "feats = [Generate.Gen2DFingerprint(x, Gobbi_Pharm2D.factory) for x in ms]\n",
    "\n",
    "# 打开（或创建）'feats.txt'文件以追加模式写入药效团指纹数据\n",
    "with open('feats.txt','a') as c:\n",
    "    for i in range(len(feats)):\n",
    "        # 将每个指纹转换为位字符串\n",
    "        str1 = feats[i].ToBitString()\n",
    "        # 遍历位字符串，并将每一位后跟逗号写入文件\n",
    "        for j in str1:\n",
    "            c.write(str(int(j))+',')\n",
    "        # 每个指纹的位字符串结束后换行\n",
    "        c.write('\\n')\n",
    "    # 文件操作完成后自动关闭\n",
    "    c.close()\n",
    "\n",
    "# 读取保存的'feats.txt'文件\n",
    "ecfp4 = open(\"feats.txt\",\"r\",encoding='utf-8') \n",
    "MF_ecfp4=[]\n",
    "# 逐行读取文件中的内容\n",
    "for line in ecfp4.readlines():\n",
    "    # 将每行按逗号分割，转换成列表\n",
    "    line=line.split(',')\n",
    "    # 将处理后的列表添加到MF_ecfp4列表中\n",
    "    MF_ecfp4.append(line)\n",
    "# 关闭文件\n",
    "ecfp4.close() \n",
    "\n",
    "# 将读取的指纹数据转换为DataFrame\n",
    "MF_ecfp4=pd.DataFrame(MF_ecfp4,index = None)\n",
    "# 删除DataFrame中最后一个空列，这个空列是由于每行结尾的逗号导致的\n",
    "MF_ecfp4 = MF_ecfp4.drop(MF_ecfp4.columns[-1],axis=1)\n",
    "\n",
    "# 从原始数据集中提取canonical_smiles和bioactivity_class列\n",
    "Y = ar2[[\"canonical_smiles\",\"bioactivity_class\"]]\n",
    "\n",
    "# 将提取的列与药效团指纹数据合并\n",
    "ar3 = pd.concat([Y,MF_ecfp4], axis=1)\n",
    "\n",
    "# 将合并后的数据保存到新的CSV文件\n",
    "ar3.to_csv('MGAM-test-feats.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usual",
   "language": "python",
   "name": "usual"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
